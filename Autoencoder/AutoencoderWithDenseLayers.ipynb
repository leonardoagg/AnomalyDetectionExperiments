{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import PIL\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf. __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutWorkSpace(img,border): \n",
    "    # dimensioni immagini\n",
    "    img_h = 2048\n",
    "    img_l = 2048\n",
    "    # offset per posizionamento su area d'indagine\n",
    "    offset_x = 600\n",
    "    offset_y = 500\n",
    "    \n",
    "    #taglio per garantire la ricerca sull'area di interesse, evitando rumori dati dallo sfondo\n",
    "    crop_img = img[offset_y:img_h-offset_y, offset_x:img_l-offset_x]\n",
    "    \n",
    "    # Convert the img to grayscale\n",
    "    gray = cv2.cvtColor(crop_img,cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    high_thresh, thresh_im = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    lowThresh = 0.5*high_thresh\n",
    "    \n",
    "    edges = cv2.Canny(blurred,20,150,apertureSize = 3)\n",
    "    \n",
    "    # This returns an array of r and theta values\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180, 100)\n",
    "    \n",
    "    i = 0\n",
    "    x_first = 0\n",
    "    x_second = 0\n",
    "    count = 0\n",
    "    delta = 35\n",
    "    thetaFinal = 0\n",
    "    while count < 2:\n",
    "        for r,theta in lines[i]:\n",
    "            # Stores the value of cos(theta) in a\n",
    "            a = np.cos(theta)\n",
    "\n",
    "            # Stores the value of sin(theta) in b\n",
    "            b = np.sin(theta)\n",
    "\n",
    "            # x0 stores the value rcos(theta)\n",
    "            x0 = a*r\n",
    "\n",
    "            # y0 stores the value rsin(theta)\n",
    "            y0 = b*r\n",
    "\n",
    "            #ti define line lenght\n",
    "            const = 3000\n",
    "            # x1 stores the rounded off value of (rcos(theta)-1000sin(theta))\n",
    "            x1 = int(x0 + const*(-b))\n",
    "\n",
    "            # y1 stores the rounded off value of (rsin(theta)+1000cos(theta))\n",
    "            y1 = int(y0 + const*(a))\n",
    "\n",
    "            # x2 stores the rounded off value of (rcos(theta)+1000sin(theta))\n",
    "            x2 = int(x0 - const*(-b))\n",
    "\n",
    "            # y2 stores the rounded off value of (rsin(theta)-1000cos(theta))\n",
    "            y2 = int(y0 - const*(a))\n",
    "\n",
    "            if count == 0 :\n",
    "                if theta != 0:\n",
    "                    thetaFinal = 180-math.degrees(theta)\n",
    "                x_first = x0\n",
    "                count += 1\n",
    "            else:\n",
    "                if abs(x_first-x0) > delta :\n",
    "                    x_second = x0\n",
    "                    count += 1\n",
    "            i += 1\n",
    "    \n",
    "    (h, w) = img.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    # rotate our image by Theta degrees around the center of the image\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), -thetaFinal, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (w, h))\n",
    "    scale_percent = 100 # percent of original size\n",
    "\n",
    "  \n",
    "    if x_first < x_second:\n",
    "        \n",
    "        median = (x_second+x_first)//2\n",
    "        temp = rotated[0:img_h-1, int(offset_x+median-border):int(offset_x+median+border)]\n",
    "        width = int(temp.shape[1] * scale_percent / 100)\n",
    "        height = int(temp.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        temp = cv2.resize(temp, dim, interpolation = cv2.INTER_AREA)        \n",
    "        gray = cv2.cvtColor(temp,cv2.COLOR_BGR2GRAY)\n",
    "        return  gray\n",
    "    else:\n",
    "        median = (x_first+x_second)//2.\n",
    "        temp = rotated[0:img_h-1, int(offset_x+median-border):int(offset_x+median+border)]        \n",
    "        #blurred = cv2.GaussianBlur(temp, (3,3), 0)\n",
    "        width = int(temp.shape[1] * scale_percent / 100)\n",
    "        height = int(temp.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        temp = cv2.resize(temp, dim, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(temp,cv2.COLOR_BGR2GRAY)\n",
    "        return  gray\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideImage(img,pcs):\n",
    "    results = []\n",
    "    lung = len(img) // pcs\n",
    "    for i in range(pcs):\n",
    "        results.append(img[(lung*i):(lung*(i+1)-1)][:])\n",
    "    final_res = []\n",
    "    for res in results:\n",
    "        final_res.append(cv2.resize(res, (rows,col), interpolation = cv2.INTER_AREA))\n",
    "    return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 32\n",
    "col = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrazione dati di input\n",
    "Estrazione e preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathBuoni = '/Users/leonardoaggio/Desktop/Dataset/S606C/Cam3@00004/*.tif'\n",
    "pathFS = '/Users/leonardoaggio/Desktop/Dataset/S606C/FalsiScarti/*.tif'\n",
    "pathBuoniVal = '/Users/leonardoaggio/Desktop/Dataset/S606C/BuoniVal/*.tif'\n",
    "pathFSVal = '/Users/leonardoaggio/Desktop/Dataset/S606C/FalsiScartiVal/*.tif'\n",
    "pathScartiVal = '/Users/leonardoaggio/Desktop/Dataset/S606C/ScartiVal/*.tif'\n",
    "\n",
    "rows = 32\n",
    "col = 32\n",
    "\n",
    "pezziXimmagine = 17\n",
    "border = 60\n",
    "\n",
    "img_train = []\n",
    "img_test = []\n",
    "\n",
    "\n",
    "list_paths = []\n",
    "\n",
    "\n",
    "\n",
    "list_paths = glob.glob(pathBuoni)\n",
    "list_paths += glob.glob(pathFS) \n",
    "\n",
    "count = 0\n",
    "for img_path in list_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    #try:\n",
    "    img_train +=  divideImage(cutWorkSpace(img,border),pezziXimmagine)\n",
    "    count += 1\n",
    "    #except:\n",
    "        #print('errore lettura')\n",
    "\n",
    "\n",
    "list_paths = glob.glob(pathBuoniVal)\n",
    "list_paths += glob.glob(pathFSVal) \n",
    "#list_paths += glob.glob(pathScartiVal) \n",
    "\n",
    "count = 0\n",
    "for img_path in list_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    try:\n",
    "        img_test +=  divideImage(cutWorkSpace(img,border),pezziXimmagine)\n",
    "        count += 1\n",
    "    except:\n",
    "        print('errore lettura')\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "# ORA HO IMG_RESULTS & RESULTS\n",
    "plt.imshow(img_test[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.array(img_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train/255.\n",
    "x_temp = np.empty((len(img_train), rows,col,1))\n",
    "x_train = x_train.astype('float32')\n",
    "for i in range(len(img_train)):\n",
    "    x_temp[i]=(np.expand_dims(x_train[i], axis=2))\n",
    "x_train = x_temp\n",
    "\n",
    "\n",
    "\n",
    "x_temp = np.empty((len(img_train), rows,col,1))\n",
    "\n",
    "\n",
    "x_temp = x_train.astype('float32')\n",
    "\n",
    "\n",
    "x_test = np.array(img_test)\n",
    "x_test = x_test/255.\n",
    "\n",
    "x_temp = np.empty((len(img_test), rows,col,1))\n",
    "for i in range(len(x_test)):\n",
    "    x_temp[i]=(np.expand_dims(x_test[i], axis=2))\n",
    "x_test = x_temp\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_test = x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Costruzione del modello di autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers \n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "inputs = tf.keras.Input(shape=(rows,col, 1), name='input_layer')\n",
    "\n",
    "encoder = layers.MaxPooling2D((2, 2),padding='same')(inputs)\n",
    "encoder = layers.Conv2D(16,kernel_size=3,activation='relu',padding='same',strides=1)(encoder)\n",
    "encoder = layers.MaxPooling2D((2, 2),padding='same')\n",
    "encoder = layers.Conv2D(32,kernel_size=3,activation='relu',padding='same',strides=1)(encoder)\n",
    "encoder = layers.MaxPooling2D((2, 2),padding='same')\n",
    "encoder = layers.Conv2D(32,kernel_size=3,activation='relu',padding='same',strides=1)(encoder)\n",
    "encoder = layers.Flatten()(encoder)\n",
    "encoder = layers.Dense(units=512,activation='sigmoid')(encoder)\n",
    "encoder = layers.Dense(units=256,activation='sigmoid')(encoder)\n",
    "encoder = layers.Dense(units=256,activation='sigmoid')(encoder)\n",
    "decoder = layers.Dense(units=512,activation='sigmoid')(encoder)\n",
    "decoder = layers.Dense(units=512,activation='sigmoid')(dencoder)\n",
    "decoder = layers.Reshape((4,4,32))(decoder)\n",
    "decoder = layers.Conv2DTranspose(32,kernel_size=3,activation='relu',padding='same',strides=1)(decoder)\n",
    "decoder = layers.UpSampling2D((2, 2))\n",
    "decoder = layers.Conv2DTranspose(16,kernel_size=3,strides=1,activation='relu',padding='same')(decoder)\n",
    "decoder = layers.UpSampling2D((2, 2))\n",
    "decoder = layers.Conv2DTranspose(1,kernel_size=3,strides=1,activation='relu',padding='same')(decoder)\n",
    "decoder = layers.UpSampling2D((2, 2))\n",
    "outputs = layers.Conv2D(1,kernel_size=(3,3),activation='sigmoid',padding='same')(decoder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione funzione di loss e training del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "    \n",
    "    y_true = tf.convert_to_tensor(y_true)\n",
    "    y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred,1.0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = 0.0005)\n",
    "\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.Model(inputs, outputs)\n",
    "autoencoder.compile(optimizer=optimizer, loss=SSIMLoss)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist=autoencoder.fit(x_train, x_train,\n",
    "                epochs=150,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('newFormatVer1',save_format='h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "autoencoder_copy = autoencoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "autoencoder_copy = tf.keras.models.load_model('newFormatVersion3', compile=False)\n",
    "autoencoder_copy.compile(optimizer=optimizer, loss=SSIMLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisi dei risultati ottenuti selle immagini del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder_copy.predict(x_train)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_train[i].reshape(rows,col))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(decoded_imgs[i].reshape(rows,col))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder_copy.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "values1 = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    print(str(i)+'/'+str(len(x_test)))\n",
    "\n",
    "\n",
    "    value_a = SSIMLoss(x_test[i],decoded_imgs[i])\n",
    "    values1.append(value_a.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo dei risultati relativi a tutte le immagini che rappresentano uno scarto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/Users/leonardoaggio/Desktop/Dataset/S606C/ScartiTotali/*.tif'\n",
    "#path = 'Desktop/Dataset/S606C/ScartiTotali/' \n",
    "border = 60\n",
    "#Nclusters = 10\n",
    "\n",
    "#results = []\n",
    "imgs = []\n",
    "\n",
    "\n",
    "list_paths = glob.glob(path) \n",
    "count = 0\n",
    "for img_path in list_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    try:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        temp = cutWorkSpace(img,border)\n",
    "        imgs +=  divideImage(temp,pezziXimmagine)\n",
    "        #plt.imshow(temp)\n",
    "        #plt.show()\n",
    "        count += 1\n",
    "    except:\n",
    "        print('errore lettura')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "x_test_final = np.array(imgs)\n",
    "x_test_final = x_test_final/255.       \n",
    "\n",
    "\n",
    "x_temp = np.empty((len(imgs), rows,col,1))\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    x_temp[i]=(np.expand_dims(x_test_final[i], axis=2))\n",
    "x_test_final = x_temp\n",
    "\n",
    "\n",
    "x_test_final = x_test_final.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs_final = autoencoder_copy.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "values2 = []\n",
    "\n",
    "for i in range(len(x_test_final)):\n",
    "    print(str(i)+ ' su '+ str(len(x_test_final)))\n",
    "    value_a = SSIMLoss(x_test_final[i],decoded_imgs_final[i])\n",
    "    values2.append(value_a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoded_imgs = autoencoder_copy.predict(x_test_final)\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(x_test_final[i+10].reshape(rows, col))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    plt.title(\"Original\")\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.imshow(decoded_imgs_final[i+10].reshape(rows, col))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "plt.imshow(x_test_final[i].reshape(rows, col))\n",
    "plt.show()\n",
    "plt.imshow(decoded_imgs_final[i].reshape(rows, col))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(values1, bins=50)  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram for Model Clf1 Anomaly Scores\")\n",
    "plt.show()\n",
    "\n",
    "#print(np.min(values1))\n",
    "\n",
    "plt.hist(values2, bins=50, color='r')  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram for Model Clf1 Anomaly Scores\")\n",
    "plt.show()\n",
    "\n",
    "print(np.max(values2))\n",
    "\n",
    "x = values1\n",
    "y = values2\n",
    "\n",
    "\n",
    "plt.hist(x, bins=50, alpha=0.5, label='Buoni', color='b')\n",
    "plt.hist(y, bins=50, alpha=0.5, label='Scarti', color = 'r')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scoreSTX = values2\n",
    "scoreSTY = []\n",
    "for i in range(len(scoreSTX)):\n",
    "    scoreSTY.append((i+1))\n",
    "    \n",
    "scoreX = values1\n",
    "scoreY = []\n",
    "for i in range(len(scoreX)):\n",
    "    scoreY.append(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione che ritorna la media dei 5 valori maggiori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxFiveAvg(list_in):\n",
    "    num = 5\n",
    "    temp = np.copy(list_in)\n",
    "    ordered = np.sort(temp)\n",
    "    avg = 0.\n",
    "    for i in range(num):\n",
    "        avg += ordered[len(list_in)-1-i]\n",
    "    avg = avg / num\n",
    "\n",
    "    return avg\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pezziXimmagine\n",
    "\n",
    "scoreSTX = []\n",
    "scoreSTY = []\n",
    "temp = 0\n",
    "for i in range(int(len(values2)/pezziXimmagine)):\n",
    "    scoreSTX.append(maxFiveAvg(values2[i*pezziXimmagine:(i*pezziXimmagine)+pezziXimmagine]))\n",
    "    scoreSTY.append(i)\n",
    "    \n",
    "scoreX = []\n",
    "scoreY = []\n",
    "for i in range(int(len(values1)/pezziXimmagine)):\n",
    "    scoreX.append(maxFiveAvg(values1[i*pezziXimmagine:(i*pezziXimmagine)+pezziXimmagine]))\n",
    "    scoreY.append(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot risultati ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "\n",
    "plt.scatter(scoreY,scoreX,label='Train Buoni',color='b')\n",
    "plt.scatter(scoreSTY,scoreSTX,label='Test Scarti',color='r')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Average log-likelihood')\n",
    "plt.title('PCA score')\n",
    "plt.savefig('LogLik.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test con threshold manuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.16\n",
    "\n",
    "falsi_scarti = 0\n",
    "for el in scoreX:\n",
    "    if el > threshold:\n",
    "        falsi_scarti += 1\n",
    "        \n",
    "scarti = 0\n",
    "for el in scoreSTX:\n",
    "    if el > threshold:\n",
    "        scarti += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test finale su dataset completo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/Users/leonardoaggio/Desktop/Dataset/Dataset/Cam3@00004v2/*.tif'\n",
    "#path = 'Desktop/Dataset/S606C/ScartiTotali/' \n",
    "border = 60\n",
    "#Nclusters = 10\n",
    "\n",
    "#results = []\n",
    "imgs = []\n",
    "\n",
    "\n",
    "list_paths = glob.glob(path) \n",
    "count = 0\n",
    "for img_path in list_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    try:\n",
    "        temp = cutWorkSpace(img,border)\n",
    "        imgs +=  divideImage(temp,pezziXimmagine)\n",
    "        #plt.imshow(temp)\n",
    "        #plt.show()\n",
    "        count += 1\n",
    "    except:\n",
    "        print('errore lettura')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "x_test_final_2 = np.array(imgs)\n",
    "x_test_final_2 = x_test_final_2/255.       \n",
    "\n",
    "\n",
    "x_temp = np.empty((len(imgs), rows,col,1))\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    x_temp[i]=(np.expand_dims(x_test_final_2[i], axis=2))\n",
    "x_test_final_2 = x_temp\n",
    "\n",
    "\n",
    "x_test_final_2 = x_test_final_2.astype('float32')\n",
    "\n",
    "decoded_imgs_final_2 = autoencoder_copy.predict(x_test_final_2)\n",
    "\n",
    "values3 = []\n",
    "\n",
    "for i in range(len(x_test_final_2)):\n",
    "    print(str(i)+ ' su '+ str(len(x_test_final_2)))\n",
    "    value_a = SSIMLoss(x_test_final_2[i],decoded_imgs_final_2[i])\n",
    "    values3.append(value_a.numpy())\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSTX_2 = []\n",
    "scoreSTY_2 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSTX_2 = values3\n",
    "scoreSTY_2 = []\n",
    "for i in range(len(scoreSTX_2)):\n",
    "    scoreSTY_2.append((i+1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0\n",
    "scoreSTX_2 = []\n",
    "scoreSTY_2 = []\n",
    "for i in range(int(len(values3)/pezziXimmagine)):\n",
    "    scoreSTX_2.append(maxFiveAvg(values3[i*pezziXimmagine:(i*pezziXimmagine)+pezziXimmagine]))\n",
    "    scoreSTY_2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falsi_scarti = 0\n",
    "for el in scoreSTX_2:\n",
    "    if el > threshold:\n",
    "        falsi_scarti += 1\n",
    "print(falsi_scarti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.scatter(scoreY,scoreX,label='Validation Buoni',color='b')\n",
    "plt.scatter(scoreSTY,scoreSTX,label='Test Scarti',color='r')\n",
    "plt.scatter(scoreSTY_2,scoreSTX_2,label='Test Buoni 2',color='g')\n",
    "\n",
    "plt.plot([-5,500],[threshold,threshold],label=('Limite identificazione scarto'))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylabel('Average log-likelihood')\n",
    "plt.title('PCA score')\n",
    "plt.savefig('LogLik.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
